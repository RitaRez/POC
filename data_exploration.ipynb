{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOepa4yERpW461K26bmWTjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RitaRez/POC/blob/main/data_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bibliotecas Utilizadas e Mount do Drive"
      ],
      "metadata": {
        "id": "aWtma7zYlA6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxPXT5rsEK52",
        "outputId": "62b732c0-78f1-4e4c-d2d8-46aaa74531fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=af80602944c61b0cc4c94cb66e12b8e6a3faaadcb816a6eb334ae9a41a3bce27\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, num2words\n",
            "Successfully installed docopt-0.6.2 num2words-0.5.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-VFyfEN2-rYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ccf6c2-3a0d-49de-b16a-704d8b39c76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import json, re, nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "from nltk import ne_chunk, pos_tag, word_tokenize\n",
        "from nltk.tree import Tree\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/My Drive/ToT/\"\n",
        "!ls \"/content/drive/My Drive/ToT\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXDm6tNk_IW5",
        "outputId": "ce31cdfa-432b-47ff-b54d-8acc52da9c67"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index  Movies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leitura de Corpus e Consultas"
      ],
      "metadata": {
        "id": "ZSDnWKJBlHRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path + 'Movies/queries.json', 'rt') as file:\n",
        "  \n",
        "  queries = []\n",
        "  for l in file:\n",
        "      queries.append(json.loads(l))\n",
        "\n",
        "queries[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTsZIbGL_LuF",
        "outputId": "c29aea3c-1140-4b85-e331-81edfad7e674"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'cggmzb',\n",
              " 'title': '[TOMT][ANIMATION] Little girl turns out to be a robot. 2000s?',\n",
              " 'description': 'Hi,\\n\\n&#x200B;\\n\\nAs a kid I saw probably a middle scene in a animated film in which a girl turns out to be a robot, feels betrayed by humans and joins other machines to fight humanity. I only saw a few scenes. Looked a lot like a Ghibli film.',\n",
              " 'url': 'https://www.reddit.com/r/tipofmytongue/comments/cggmzb/tomtanimation_little_girl_turns_out_to_be_a_robot/'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path + 'Movies/documents.json', 'rt') as file:\n",
        "  \n",
        "  docs = []\n",
        "  for l in file:\n",
        "      docs.append(json.loads(l))\n",
        "\n",
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQf371kwLkmS",
        "outputId": "6c178672-66bf-4a4f-b1a3-be5fcba90230"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'tt0478303',\n",
              " 'text': 'Seven strangers visiting Hollywood movie studios are locked inside an ill-famed House of Horror.\\nTo leave the trap alive, they have to tell their most terrifying stories.',\n",
              " 'title': 'Trapped Ashes',\n",
              " 'meta': {'wikidata_id': 'Q3538057'}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qual a proporção de consultas que apresentam referencias temporais?\n",
        "\n",
        "É importante lembrar que esses números podem se referir a época onde se passa o filme ou até mesmo números que não representam datas."
      ],
      "metadata": {
        "id": "U9RmEtillOtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_time_references = r\"\\b(20)?(\\d{2})[']?s?\\b|\\b(20)?(\\d{2})\\b\"\n",
        "\n",
        "print(queries[4]['title'], \" Match: \", re.search(numeric_time_references, queries[4]['title']))\n",
        "print(queries[5]['title'], \" Match: \", re.search(numeric_time_references, queries[5]['title']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOpKtKEz_zGb",
        "outputId": "9f05983f-2478-4d72-e454-08615b3fa144"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TOMT] [MOVIE] Horror film based on true story which I'm almost certain starred Richard Thomas from The Waltons  Match:  None\n",
            "[TOMT][MOVIE][Early 2000s]Movie in which two perfect strangers have casual sex but everything ends when one of the two tries to know more about the other  Match:  <re.Match object; span=(20, 25), match='2000s'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for query in queries:\n",
        "  if re.search(numeric_time_references, query['title']):\n",
        "    count += 1\n",
        "\n",
        "print(f\"{100*count/len(queries)}% of queries have some form of time frame in the title\")\n",
        "\n",
        "count = 0\n",
        "for query in queries:\n",
        "  if  re.search(numeric_time_references, query['description']):\n",
        "    count += 1\n",
        "\n",
        "print(f\"{100*count/len(queries)}% of queries have some form of time frame in the description\")\n",
        "\n",
        "count = 0\n",
        "for query in queries:\n",
        "  if re.search(numeric_time_references, query['description']) or re.search(numeric_time_references, querie['title']):\n",
        "    count += 1\n",
        "\n",
        "print(f\"{100*count/len(queries)}% of queries have some form of time frame in the title or the description\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZh7JjD5HKDA",
        "outputId": "77e4c532-ebdf-49a2-a60e-ce38d167202e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41.79669395952418% of queries have some form of time frame in the title\n",
            "41.75807199134868% of queries have some form of time frame in the description\n",
            "100.0% of queries have some form of time frame in the title or the description\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qual a proporção de consultas que apresentam referências a nomes próprios?\n",
        "\n",
        "Podem ser referencias a atores, diretores, personagens..."
      ],
      "metadata": {
        "id": "2jp_A1Ifls-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_results = ne_chunk(pos_tag(word_tokenize(queries[1]['description'])))\n",
        "for nltk_result in nltk_results:\n",
        "    if type(nltk_result) == Tree:\n",
        "        name = ''\n",
        "        for nltk_result_leaf in nltk_result.leaves():\n",
        "            name += nltk_result_leaf[0] + ' '\n",
        "        if nltk_result.label() == 'PERSON':\n",
        "          print ('Type: ', nltk_result.label(), 'Name: ', name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OXwOq6ymoFE",
        "outputId": "b9ddcbd0-ed7e-402f-c1c2-4d55eaa0307e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type:  PERSON Name:  Born \n",
            "Type:  PERSON Name:  Matilda \n",
            "Type:  PERSON Name:  Matilda \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for query in queries:\n",
        "  nltk_results = ne_chunk(pos_tag(word_tokenize(query['title'] + query['description'])))\n",
        "  for nltk_result in nltk_results:\n",
        "    if type(nltk_result) == Tree:\n",
        "      name = ''\n",
        "      for nltk_result_leaf in nltk_result.leaves():\n",
        "        name += nltk_result_leaf[0] + ' '\n",
        "      if nltk_result.label() == 'PERSON':\n",
        "        count += 1\n",
        "\n",
        "print(f\"{100*count/len(queries)}% of queries have some form of person name in the title or the description\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGBSkr3MoPbN",
        "outputId": "5345702a-b0ba-49ff-e1a5-1e33f83b25a1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67.48030279623049% of queries have some form of person name in the title or the description\n"
          ]
        }
      ]
    }
  ]
}